{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de marcadores en una escena\n",
    "### y su reemplazo por una imagen sustituto puesta en perspectiva y posicionamiento de una nube de puntos\n",
    "\n",
    "Notebook demo de la estrategia propuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencias:\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "#funciones para reconocer y reemplazar glifos en una escena\n",
    "import ar_functions as ar\n",
    "#funciones utilziadas para el manejo de una nube de puntos\n",
    "import point_cloud_functions as pc\n",
    "#base de datos de los glifos y los objetos de AR que representan\n",
    "import glyph_database as db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#umbral de luminancia para considerar a un pixel como negro\n",
    "BLACK_THRESHOLD = 50\n",
    "#umbral de luminancia para considerar a un pixel como blanco\n",
    "WHITE_THRESHOLD = 120\n",
    "#máxima cantidad de glifos en una escena\n",
    "GLYPHS_ON_THE_SCENE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta demostración permite reemplazar glifos en la escena por imágenes .png o nubes de puntos. Para facilitar el manejo de la nube de puntos se decidió copiar la información de los vértices de un archivo .obj (que se puede abrir en formato ASCII) en un archivo .txt. \n",
    "\n",
    "El diccionario __GLYPH_TABLE__ hallado en el archivo *glyph_database.py* funciona sólo para asociar los códigos binarios de los glifos con los objetos de realidad aumentada que les corresponden. Previo al análisis de la escena, se cargan los archivos en memoria. Las operaciones más costosas son las relacionadas al manejo de la nube de puntos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diccionario a cargar con imagenes y nubes de puntos\n",
    "glyphs_data = {}\n",
    "\n",
    "#se lee db.GLYPH_TABLE y se cargan los archivos indicados\n",
    "for (label,kind) in db.GLYPH_TABLE.values() :\n",
    "    if kind == \"png\" : \n",
    "        glyphs_data[label] = cv2.imread('images/{}.png'.format(label))\n",
    "    elif kind == \"point_cloud\" :\n",
    "        cloud = pc.text2cloud('images/{}.txt'.format(label) )\n",
    "        #rotación arbitraria\n",
    "        cloud = pc.rotate_y( cloud, math.pi/2)\n",
    "        cloud = pc.rotate_x( cloud, -math.pi/20)\n",
    "        cloud = pc.rotate_z( cloud, math.pi*5/9)\n",
    "        glyphs_data[label] = cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementa una funcion auxiliar para visualizar los resultados en este notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    #si la imagen tiene 3 canales:\n",
    "    if len( image.shape ) == 3 : \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        cmap = None\n",
    "    #si la imagen tiene 1 canal (no se trabaja con imagenes de otra cantidad de canales):\n",
    "    else : \n",
    "        cmap = \"gray\"\n",
    "        \n",
    "    plt.axis(\"off\")    \n",
    "    plt.imshow(image, cmap = cmap)\n",
    "    plt.show()\n",
    "    \n",
    "#configuración de figuras en el notebook\n",
    "side = 20\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [side, side]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee la imagen de la escena y se obtiene una version en escala de grises para hacer el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('glyph_scene.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desean reconocer los cuadrilateros de la escena, que son los candidatos a glifos para reemplazar. Para esto se debe tener información de los bordes detectados en la escena (calculados con cv2.Canny). Previamente a la detección de bordes se hace un blur de la escena con cv2.GaussianBlur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "edges = cv2.Canny(blur, 100, 200)\n",
    "show_image(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función cv2.findContours se buscan los contornos cerrados presentes en la escena y sólo se analizan los 10 contornos con mayor área."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse=True)[:GLYPHS_ON_THE_SCENE]\n",
    "img_w_edges = img.copy()\n",
    "cv2.drawContours(img_w_edges, contours, -1, (0,255,0), 3)\n",
    "show_image(img_w_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo interesa analizar los contornos que tienen 4 lados (como los marcadores posibles). A estos contornos se les es aplicada una transformación de perspectiva para poder tener una vista frontal y facilitar su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista a llenar con contornos cuadrilateros\n",
    "quads = []\n",
    "\n",
    "#se recorre la lista de contornos\n",
    "for i,contour in enumerate(contours):  \n",
    "    #se analiza el peremitro y la cantidad de vertices del contorno\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.01*perimeter, True)\n",
    "\n",
    "    #se agrega el contorno a la lista quads si este tiene 4 lados.\n",
    "    #ya que cv2.findContours puede encontrar contornos duplicados pero con orientación diferente,\n",
    "    #se utiliza el signo del resultado de cv2.contourArea para sólo quedarse con un contorno posible\n",
    "    if (len(approx) == 4) and (cv2.contourArea(contour,True) > 0):\n",
    "        #se redimensiona el arreglo de vértices para que tenga 4 elementos de la forma x,y\n",
    "        approx = approx.reshape(4, 2)\n",
    "        #transformación de perspectiva\n",
    "        topdown_quad = ar.get_topdown_quad(gray, approx)\n",
    "        quads.append( [topdown_quad, approx] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos los marcadores encontrados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crea una figura con tantos cuadriláteros como los encontrados\n",
    "rows = len(quads)\n",
    "fig, axs = plt.subplots(rows)\n",
    "\n",
    "#plot\n",
    "for i, (quad, approx) in enumerate(quads) :\n",
    "        axs[i].axis(\"off\")\n",
    "        axs[i].imshow(quad, cmap = \"gray\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se verifica la validez de los glifos encontrados (es decir que poseen una frontera de celdas negras) y se hace el reemplazo en la escena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se recorre quads\n",
    "for i, (quad, approx) in enumerate(quads):\n",
    "    #se obtiene el código binario que representa esa imagen\n",
    "    glyph_pattern = ar.get_glyph_pattern(quad, BLACK_THRESHOLD, WHITE_THRESHOLD) \n",
    "    #se verifica que el código binario represente un glifo\n",
    "    valid_glyph = ar.is_valid_glyph(glyph_pattern)\n",
    "    #si el código binario es válido:\n",
    "    if (valid_glyph) :\n",
    "        #se recortan las 5 celdas de la frontera\n",
    "        glyph_code = [ row[1:ar.CELLS_IN_A_GLYPH-1] for row in glyph_pattern[1:ar.CELLS_IN_A_GLYPH-1] ]\n",
    "        #se busca en la base de datos por qué se debe reemplazar el marcador\n",
    "        glyph_found, (label, kind) = db.match_glyph_pattern(glyph_code)\n",
    "        #si el marcador debe ser reemplazado:\n",
    "        if glyph_found:\n",
    "            #si se debe reemplazar por una imagen:\n",
    "            if kind == \"png\" :\n",
    "                img, dst_points  = ar.add_substitute_quad( img, glyphs_data[ label ], approx.reshape(4,2))\n",
    "            #si se debe reemplazar por una nube de puntos:\n",
    "            elif kind == \"point_cloud\" :\n",
    "                img = ar.add_substitute_cloud(img, glyphs_data[ label ], approx.reshape(4,2)  )\n",
    "            \n",
    "show_image(img)     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
